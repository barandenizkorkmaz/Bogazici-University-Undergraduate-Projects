{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yBTqdG1LzhC"
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRq4myVuMY9W",
        "outputId": "cc9a1074-0486-4728-8648-27cb76d22003"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8GhlR_5MqHh"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JV0lhr3UONHX"
      },
      "source": [
        "!pip install -U sentence-transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hKZJ6VvOST_"
      },
      "source": [
        "!pip install bert-tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qn8EqZtOgED"
      },
      "source": [
        "!pip install tensorflow-gpu==1.15.0\n",
        "!pip install bert-tensorflow\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from datetime import datetime\n",
        "import bert\n",
        "from bert import run_classifier\n",
        "from bert import optimization\n",
        "from bert import tokenization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCUPUHixXhku",
        "outputId": "82b9144f-9e3f-4000-b1e0-e32d3268c935"
      },
      "source": [
        "!wget \"https://ir.nist.gov/covidSubmit/data/topics-rnd5.xml\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-28 19:00:32--  https://ir.nist.gov/covidSubmit/data/topics-rnd5.xml\n",
            "Resolving ir.nist.gov (ir.nist.gov)... 129.6.24.92, 2610:20:6005:24::92\n",
            "Connecting to ir.nist.gov (ir.nist.gov)|129.6.24.92|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18707 (18K) [application/xml]\n",
            "Saving to: ‘topics-rnd5.xml’\n",
            "\n",
            "\rtopics-rnd5.xml       0%[                    ]       0  --.-KB/s               \rtopics-rnd5.xml     100%[===================>]  18.27K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2021-01-28 19:00:32 (1.82 MB/s) - ‘topics-rnd5.xml’ saved [18707/18707]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWlz4t_8nFpf",
        "outputId": "499d42b5-504c-4b19-9260-9dd7a8f5bf6f"
      },
      "source": [
        "!wget \"https://ir.nist.gov/covidSubmit/data/qrels-covid_d5_j0.5-5.txt\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-28 20:08:29--  https://ir.nist.gov/covidSubmit/data/qrels-covid_d5_j0.5-5.txt\n",
            "Resolving ir.nist.gov (ir.nist.gov)... 129.6.24.92, 2610:20:6005:24::92\n",
            "Connecting to ir.nist.gov (ir.nist.gov)|129.6.24.92|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1142244 (1.1M) [text/plain]\n",
            "Saving to: ‘qrels-covid_d5_j0.5-5.txt’\n",
            "\n",
            "qrels-covid_d5_j0.5 100%[===================>]   1.09M  1.72MB/s    in 0.6s    \n",
            "\n",
            "2021-01-28 20:08:30 (1.72 MB/s) - ‘qrels-covid_d5_j0.5-5.txt’ saved [1142244/1142244]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWHVVZJBnMJ8"
      },
      "source": [
        "FILE_EVALUATE = \"qrels-covid_d5_j0.5-5.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0VkcooEPeSv"
      },
      "source": [
        "import os\n",
        "\n",
        "def searchExistingFile(file_name):\n",
        "    return os.path.exists(file_name)\n",
        "\n",
        "def getCorpusList(docs:dict):\n",
        "    docIds = getDocIds(docs) # Sorted\n",
        "    corpus = list()\n",
        "    for docId in docIds:\n",
        "        textList = list()\n",
        "        title = docs[docId]['TITLE']\n",
        "        abstract = docs[docId]['ABSTRACT']\n",
        "        for elem in title:\n",
        "            textList.append(elem)\n",
        "        for elem in abstract:\n",
        "            textList.append(elem)\n",
        "        corpus.append(' '.join(textList))\n",
        "    return corpus\n",
        "\n",
        "def getDocIds(docs:dict):\n",
        "    return sorted(docs.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5FK9QiqO_Vm"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import pickle\n",
        "import csv\n",
        "\n",
        "# REFERENCE: https://stackoverflow.com/questions/52937859/read-csv-file-line-by-line-python\n",
        "def tokenization(file_name='/content/drive/My Drive/metadata.csv'):\n",
        "    docs = dict()\n",
        "    with open (file_name,'r') as csv_file:\n",
        "        reader =csv.reader(csv_file)\n",
        "        next(reader) # skip first row\n",
        "        for row in reader:\n",
        "            cord_uid = row[0]\n",
        "            title = row[3]\n",
        "            abstract = row[8]\n",
        "            if cord_uid in docs:\n",
        "                if len(title) > len(docs[cord_uid]['TITLE']):\n",
        "                    docs[cord_uid]['TITLE'] = title\n",
        "                if len(abstract) > len(docs[cord_uid]['ABSTRACT']):\n",
        "                    docs[cord_uid]['ABSTRACT'] = abstract\n",
        "            else:\n",
        "                docs[cord_uid] = {'TITLE': title,\n",
        "                              'ABSTRACT': abstract}\n",
        "    for docId in docs:\n",
        "        title = docs[docId]['TITLE']\n",
        "        abstract = docs[docId]['ABSTRACT']\n",
        "        docs[docId]['TITLE'] = title.split()\n",
        "        docs[docId]['ABSTRACT'] = abstract.split()\n",
        "    return docs\n",
        "\n",
        "def saveDocs(docs,fileName = '/content/drive/My Drive/TREC-COVID_DOCS.pickle'):\n",
        "    with open(fileName, 'wb') as f:\n",
        "        pickle.dump(docs, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "def loadDocs(fileName = '/content/drive/My Drive/TREC-COVID_DOCS.pickle'):\n",
        "    with open(fileName, 'rb') as f:\n",
        "        return pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yrauJCxWwGH"
      },
      "source": [
        "import math\n",
        "import string\n",
        "import xml.etree.ElementTree as ET\n",
        "import json\n",
        "import pickle\n",
        "\n",
        "def getQueries():\n",
        "    tree = ET.parse('topics-rnd5.xml')\n",
        "    root = tree.getroot()\n",
        "    queryDict = dict()\n",
        "    for child in root.findall('topic'):\n",
        "        id = child.get('number')\n",
        "        queryDict[id] = {}\n",
        "        queryDict[id]['query'] = child.find('query').text\n",
        "        queryDict[id]['question'] = child.find('question').text\n",
        "        queryDict[id]['narrative'] = child.find('narrative').text\n",
        "    return queryDict\n",
        "\n",
        "def getQuerySet(subset:str):\n",
        "    queries = getQueries()\n",
        "    querySet = dict()\n",
        "    if subset.lower() == \"training\":\n",
        "        for key in queries:\n",
        "            if int(key) % 2 == 1:\n",
        "                querySet[key] = queries[key]['query'] + \" \" + queries[key]['question'] + \" \" + queries[key]['narrative']\n",
        "    elif subset.lower() == \"test\":\n",
        "        for key in queries:\n",
        "            if int(key) % 2 == 0:\n",
        "                querySet[key] = queries[key]['query'] + \" \" + queries[key]['question'] + \" \" + queries[key]['narrative']\n",
        "    else:\n",
        "        for key in queries:\n",
        "            querySet[key] = queries[key]['query'] + \" \" + queries[key]['question'] + \" \" + queries[key]['narrative']\n",
        "    return querySet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFnVIjfoo-ri"
      },
      "source": [
        "dict_evaluate = dict()\n",
        "def fill_evaluate():\n",
        "  with open(FILE_EVALUATE, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "    for line in lines:\n",
        "      list_temp = line.split()\n",
        "      query_id = list_temp[0]\n",
        "      if query_id not in dict_evaluate:\n",
        "        dict_evaluate[query_id] = list()\n",
        "        dict_evaluate[query_id].append(list_temp[2])\n",
        "      else:\n",
        "        dict_evaluate[query_id].append(list_temp[2])\n",
        "\n",
        "fill_evaluate()    \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJWl1xINYp-J"
      },
      "source": [
        "def getResultsFile(topKResults:dict):\n",
        "    # FORMAT: query-id Q0 document-id rank score STANDARD\n",
        "    with open('/content/drive/My Drive/RESULTS', 'w') as f:\n",
        "        for queryId in topKResults:\n",
        "            for i, resTuple in enumerate(topKResults[queryId]):\n",
        "                docId = resTuple[0]\n",
        "                if docId in dict_evaluate[queryId]:\n",
        "                  cosineSimilarity = resTuple[1]\n",
        "                  print(\"%s\\tQ0\\t%s\\t%d\\t%f\\tSTANDARD\" % (queryId,docId,rank,cosineSimilarity), file=f)\n",
        "                rank = i + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ih7E2eqKIoBl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "outputId": "5139df93-18ea-4869-da0a-69acb44b18f1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    582\u001b[0m         \"\"\"\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    260\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dfs-auth-dance'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfifo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfifo_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m           \u001b[0mfifo_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth_prompt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m       \u001b[0mwrote_to_fifo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXn2wuhgQaTT",
        "outputId": "74010bc8-2f42-456e-b384-e16438955a5b"
      },
      "source": [
        "isDocsFound = searchExistingFile('/content/drive/My Drive/TREC-COVID_DOCS.pickle')\n",
        "print(\"Is 'TREC-COVID_DOCS.pickle' found?: \",isDocsFound)\n",
        "\n",
        "if not isDocsFound:\n",
        "    docs = tokenization()\n",
        "    print(\"Tokenization has been successfully done...\")\n",
        "    saveDocs(docs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Is 'TREC-COVID_DOCS.pickle' found?:  False\n",
            "Tokenization has been successfully done...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Fi6bXIpRpRs"
      },
      "source": [
        "docs = loadDocs()\n",
        "docIds = getDocIds(docs)\n",
        "corpus = getCorpusList(docs)\n",
        "del docs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXH8JYonR0wR",
        "outputId": "acd4bad1-cba0-4109-b455-59e9fb2fef26"
      },
      "source": [
        "print(\"Corpus loaded.\")\n",
        "sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
        "document_embeddings = sbert_model.encode(corpus)\n",
        "print(\"Document embeddings calculated.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corpus loaded.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 405M/405M [00:14<00:00, 27.8MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Document embeddings calculated.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3Wkj-PsWlWX"
      },
      "source": [
        "querySet = getQuerySet(\"all\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KICbdK4DYBeM"
      },
      "source": [
        "results = dict()\n",
        "for queryId, queryStr in querySet.items():\n",
        "    query_embedding = sbert_model.encode(queryStr)\n",
        "    cosineSimilarityVector = cosine_similarity(query_embedding,document_embeddings)[0]\n",
        "    queryResult = list()\n",
        "    for docId, cosineSimilarity in zip(docIds, cosineSimilarityVector):\n",
        "        queryResult.append([docId,cosineSimilarity])\n",
        "    results[queryId] = queryResult"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ej1CcEPPYXWW"
      },
      "source": [
        "# Rank documents for each query by cosineSimilarity. (For analysis purposes)\n",
        "for queryId in results:\n",
        "    resultsList = results[queryId]\n",
        "    resultsList.sort(key=lambda x: x[1], reverse=True)\n",
        "    results[queryId] = resultsList"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPkJErwyYlP5"
      },
      "source": [
        "getResultsFile(results)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}